{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r\n",
    "import sys,json, os\n",
    "import kfp\n",
    "import kfp.dsl as dsl\n",
    "from kfp import components\n",
    "import kfp.compiler as compiler\n",
    "import kfp.dsl as dsl\n",
    "from kubernetes import client as k8s_client\n",
    "\n",
    "import string\n",
    "import random\n",
    "import time\n",
    "\n",
    "from dkube.sdk import *\n",
    "from dkube.sdk.api import DkubeApi\n",
    "from dkube.sdk.rsrcs import DkubeModelmonitor\n",
    "from dkube.sdk.rsrcs.operator import DkubeCluster\n",
    "from dkube.sdk.rsrcs.modelmonitor import DatasetClass,ModelType,DriftAlgo\n",
    "from dkube.sdk.rsrcs.modelmonitor import DatasetFormat,DkubeModelmonitorAlert, TimeZone\n",
    "from dkube.sdk.rsrcs.modelmonitor import DataType, ChannelOrder, ImageDataSavedFileFormat\n",
    "\n",
    "job_class = os.getenv(\"DKUBE_JOB_CLASS\")\n",
    "if not job_class:\n",
    "    !{sys.executable} -m pip install kfp==1.4.0 kfp-server-api==1.2.0 --user >/dev/null\n",
    "\n",
    "# Set up font definitions for output\n",
    "class style:\n",
    "   RED = '\\033[91m\\033[1m'\n",
    "   BOLD = '\\033[1m'\n",
    "   END = '\\033[0m'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Configuration Variables from Resources Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONITOR_NAME = image_exp_config['MONITOR_NAME']\n",
    "INPUT_TRAIN_TYPE = image_exp_config['INPUT_TRAIN_TYPE']\n",
    "SERVING_DKUBE_USERNAME = image_exp_config['SERVING_DKUBE_USERNAME']\n",
    "TRAINING_DATASET = image_exp_config['TRAINING_DATASET']\n",
    "DKUBE_TRAINING_CODE_NAME = image_exp_config['DKUBE_TRAINING_CODE_NAME']\n",
    "SERVING_DKUBE_URL = image_exp_config['SERVING_DKUBE_URL']\n",
    "SERVING_DKUBE_TOKEN = image_exp_config['SERVING_DKUBE_TOKEN']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_deployment_running(deployment_id):\n",
    "    status = None\n",
    "    inference_url, inference = None, None\n",
    "    while True:\n",
    "        data = serving_api.get_deployment(deployment_id)\n",
    "        status = data.data.inferenceservice_deployment.parameters.generated.status.state\n",
    "        inference = data.data.inferenceservice_deployment.parameters.inference\n",
    "        inference_url = data.data.inferenceservice_deployment.parameters.generated.details.serving.servingurl\n",
    "        if status == \"RUNNING\":\n",
    "            break\n",
    "        print(\"waiting for deployment to be running\")\n",
    "        time.sleep(serving_api.wait_interval)\n",
    "    return inference, inference_url"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dkube_preprocessing_op = components.load_component_from_file(\"/mnt/dkube/pipeline/components/preprocess/component.yaml\")\n",
    "dkube_training_op = components.load_component_from_file(\"/mnt/dkube/pipeline/components/training/component.yaml\")\n",
    "dkube_serving_op  = components.load_component_from_file(\"/mnt/dkube/pipeline/components/serving/component.yaml\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = DkubeApi(URL=SERVING_DKUBE_URL, token=SERVING_DKUBE_TOKEN)\n",
    "client = kfp.Client(\n",
    "    host=os.getenv(\"KF_PIPELINES_ENDPOINT\"),\n",
    "    existing_token=SERVING_DKUBE_TOKEN,\n",
    "    namespace=SERVING_DKUBE_USERNAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_training_dataset = TRAINING_DATASET\n",
    "training_program = DKUBE_TRAINING_CODE_NAME\n",
    "\n",
    "## Training stage inputs\n",
    "input_dataset_mount = ['/data']\n",
    "training_script = \"python image_cloudevents/training.py\"\n",
    "model_name = MONITOR_NAME\n",
    "output_model_mount = \"/model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(\n",
    "    name='xray-pipeline',\n",
    "    description='xray-training-pl'\n",
    ")\n",
    "def xray_pipeline(token):    \n",
    "    train       = dkube_training_op(container=json.dumps({\"image\": \"ocdr/dkube-datascience-tf-cpu:v2.0.0-17\"}),\n",
    "                                    framework=\"tensorflow\", version=\"2.0.0\",\n",
    "                                    program=str(training_program), \n",
    "                                    run_script=str(training_script),\n",
    "                                    datasets=json.dumps([str(input_training_dataset)]), \n",
    "                                    outputs=json.dumps([str(model_name)]),\n",
    "                                    input_dataset_mounts=json.dumps(input_dataset_mount),\n",
    "                                    output_mounts=json.dumps([str(output_model_mount)]),\n",
    "                                    auth_token=token)\n",
    "    \n",
    "    serving     = dkube_serving_op(model=train.outputs['artifact'], device='cpu',\n",
    "                                    name=MONITOR_NAME,\n",
    "                                    serving_image=json.dumps({\"image\": \"ocdr/tensorflowserver:2.0.0\"}),\n",
    "                                    auth_token=token, min_replicas = '1',\n",
    "                                    production=\"true\").after(train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Pipeline Run to Deploy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the deployed model already exists\n",
    "# If not, create the pipeline run to train and deploy the model\n",
    "serving_api = DkubeApi(URL=SERVING_DKUBE_URL,token=SERVING_DKUBE_TOKEN)\n",
    "SERVING_DEPLOYMENT_ID = serving_api.get_deployment_id(name=MONITOR_NAME)\n",
    "\n",
    "# Create pipeline run name\n",
    "res = ''.join(random.choices(string.ascii_lowercase + string.digits, k=4))\n",
    "run_name = f\"{SERVING_DKUBE_USERNAME}-chest-xray-%s\"%res\n",
    "\n",
    "# Create and run the pipeline\n",
    "if not SERVING_DEPLOYMENT_ID:\n",
    "    client.create_run_from_pipeline_func(xray_pipeline, run_name=run_name, arguments={'token':SERVING_DKUBE_TOKEN})\n",
    "else:\n",
    "    print(f\"{style.BOLD}Deployment already exists, skipping training and deployment{style.END}\")\n",
    "\n",
    "# Wait for serving deployment to come up\n",
    "while True:\n",
    "    SERVING_DEPLOYMENT_ID = serving_api.get_deployment_id(name=MONITOR_NAME)\n",
    "    if SERVING_DEPLOYMENT_ID:\n",
    "        break\n",
    "    print(\"waiting for deployment to come up\")\n",
    "    time.sleep(serving_api.wait_interval)\n",
    "inference, INFERENCE_URL = wait_for_deployment_running(SERVING_DEPLOYMENT_ID)\n",
    "\n",
    "# Enable inference logs\n",
    "if not inference.enable_logs:\n",
    "    print(\"Enabling logs\")\n",
    "    serving = DkubeServing(user=SERVING_DKUBE_USERNAME, name=MONITOR_NAME)\n",
    "    serving.update_enable_logs(enable_logs=True)\n",
    "    serving_api.update_inference(serving)\n",
    "\n",
    "# Save deployment url & ID\n",
    "print(\"Inference is up at URL: \", INFERENCE_URL)\n",
    "image_exp_config['INFERENCE_URL'] = INFERENCE_URL\n",
    "image_exp_config['SERVING_DEPLOYMENT_ID'] = SERVING_DEPLOYMENT_ID\n",
    "%store image_exp_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fields used for Configuring the Monitor through the UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the instructions for the required fields in the UI-Based setup\n",
    "print()\n",
    "print(f\"{style.BOLD}Note: The Deployment ID will be needed as an input during the UI-Based configuration process{style.END}\")\n",
    "print(f\"{style.RED}Deployment ID (for Prefix Fields) = {style.END}\", SERVING_DEPLOYMENT_ID)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (main, Sep 15 2022, 01:51:29) [Clang 14.0.0 (clang-1400.0.29.102)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
