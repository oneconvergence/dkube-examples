{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r\n",
    "import sys,json, os\n",
    "job_class = os.getenv(\"DKUBE_JOB_CLASS\")\n",
    "if not job_class:\n",
    "    !{sys.executable} -m pip install kfp==1.4.0 kfp-server-api==1.2.0 --user >/dev/null\n",
    "    !{sys.executable} -m pip install git+https://github.com/oneconvergence/dkube.git@3.3 --upgrade --user >/dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import kfp\n",
    "import kfp.dsl as dsl\n",
    "import kfp.compiler as compiler\n",
    "from kfp import components\n",
    "from kubernetes import client as k8s_client\n",
    "\n",
    "import os\n",
    "import kfp\n",
    "import string\n",
    "import random\n",
    "import kfp.dsl as dsl\n",
    "import kfp.compiler as compiler\n",
    "from kfp import components\n",
    "from kubernetes import client as k8s_client\n",
    "\n",
    "from dkube.sdk.api import DkubeApi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dkube_preprocessing_op = components.load_component_from_file(\"/mnt/dkube/pipeline/components/preprocess/component.yaml\")\n",
    "dkube_training_op = components.load_component_from_file(\"/mnt/dkube/pipeline/components/training/component.yaml\")\n",
    "dkube_serving_op  = components.load_component_from_file(\"/mnt/dkube/pipeline/components/serving/component.yaml\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = DkubeApi(token=os.getenv(\"DKUBE_USER_ACCESS_TOKEN\",TOKEN))\n",
    "client = kfp.Client(\n",
    "    host=os.getenv(\"KF_PIPELINES_ENDPOINT\"),\n",
    "    existing_token=os.getenv(\"DKUBE_USER_ACCESS_TOKEN\",TOKEN),\n",
    "    namespace=DKUBEUSERNAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_training_dataset = TRAINING_DATASET\n",
    "training_program = DKUBE_TRAINING_CODE_NAME\n",
    "## Training stage inputs\n",
    "input_dataset_mount = ['/data']\n",
    "training_script = \"python image_cloudevents/training.py\"\n",
    "model_name = MODEL_NAME\n",
    "output_model_mount = \"/model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(\n",
    "    name='xray-pipeline',\n",
    "    description='xray-training-pl'\n",
    ")\n",
    "def xray_pipeline(token):    \n",
    "    train       = dkube_training_op(container=json.dumps({\"image\": \"ocdr/dkube-datascience-tf-cpu:v2.0.0-10\"}),\n",
    "                                    framework=\"tensorflow\", version=\"2.0.0\",\n",
    "                                    program=str(training_program), \n",
    "                                    run_script=str(training_script),\n",
    "                                    datasets=json.dumps([str(input_training_dataset)]), \n",
    "                                    outputs=json.dumps([str(model_name)]),\n",
    "                                    input_dataset_mounts=json.dumps(input_dataset_mount),\n",
    "                                    output_mounts=json.dumps([str(output_model_mount)]),\n",
    "                                    auth_token=token)\n",
    "    \n",
    "    serving     = dkube_serving_op(model=train.outputs['artifact'], device='cpu',\n",
    "                                    name=MONITOR_NAME,\n",
    "                                    serving_image=json.dumps({\"image\": \"ocdr/tensorflowserver:2.0.0\"}),\n",
    "                                    auth_token=token).after(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_id = api.get_deployment_id(name=MONITOR_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not deployment_id:\n",
    "    client.create_run_from_pipeline_func(xray_pipeline, arguments={'token':TOKEN})\n",
    "else:\n",
    "    print(\"Deployment Already Existing, skipping create\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
