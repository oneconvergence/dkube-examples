{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install kfp==1.4.0 kfp-server-api==1.2.0 --user >/dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import kfp\n",
    "import kfp.dsl as dsl\n",
    "import kfp.compiler as compiler\n",
    "from kfp import components\n",
    "from kubernetes import client as k8s_client\n",
    "\n",
    "import os\n",
    "import json\n",
    "import kfp\n",
    "import string\n",
    "import random\n",
    "import kfp.dsl as dsl\n",
    "import kfp.compiler as compiler\n",
    "from kfp import components\n",
    "from kubernetes import client as k8s_client\n",
    "\n",
    "from dkube.sdk.api import DkubeApi\n",
    "from dkube.sdk.rsrcs import DkubeCode\n",
    "from dkube.sdk.rsrcs import DkubeDataset\n",
    "from dkube.sdk.rsrcs import DkubeModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dkube_preprocessing_op = components.load_component_from_file(\"/mnt/dkube/pipeline/components/preprocess/component.yaml\")\n",
    "dkube_training_op = components.load_component_from_file(\"/mnt/dkube/pipeline/components/training/component.yaml\")\n",
    "dkube_serving_op  = components.load_component_from_file(\"/mnt/dkube/pipeline/components/serving/component.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = os.getenv('USERNAME')\n",
    "token = os.getenv(\"DKUBE_USER_ACCESS_TOKEN\")\n",
    "client = kfp.Client(host=os.getenv(\"KF_PIPELINES_ENDPOINT\"), existing_token=token, namespace=os.getenv(\"USERNAME\"))\n",
    "\n",
    "api = DkubeApi(token=token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Retraining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model = DkubeModel(user, name='mm-retrained-model')\n",
    "    model.update_model_source(source='dvs')\n",
    "    api.create_model(model)\n",
    "\n",
    "except Exception as e:\n",
    "    if e.reason.lower()!=\"conflict\":\n",
    "        response = e.body\n",
    "        print(f\"Failed[{response.code}]: {response.message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_program = 'mm-demo'\n",
    "input_training_dataset = ['mm-demo-groundtruth']\n",
    "input_dataset_mount = ['/data/GT-predict']\n",
    "output_dataset = 'mm-training-data'\n",
    "output_mount_path = ['/retrain-data']\n",
    "model = 'mm-training-model'\n",
    "output_model = 'mm-retrained-model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_script = 'python insurance/modeltraining/retrain-preprocessing.py'\n",
    "training_script = 'python insurance/modeltraining/retraining.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(\n",
    "    name='retraining-pipeline',\n",
    "    description='insurance-retraining-pl'\n",
    ")\n",
    "def insurance_retraining_pipeline(token):\n",
    "\n",
    "    \n",
    "    preprocessing = dkube_preprocessing_op(\n",
    "                                    auth_token=str(token),\n",
    "                                    container=json.dumps({\"image\": \"ocdr/d3-datascience-sklearn:v0.23.2-1\"}),\n",
    "                                    program=str(training_program),\n",
    "                                    datasets = json.dumps(input_training_dataset),\n",
    "                                    input_dataset_mounts = json.dumps(input_dataset_mount),\n",
    "                                    run_script=str(preprocessing_script),\n",
    "                                    outputs=json.dumps([str(output_dataset)]),\n",
    "                                    output_mounts=json.dumps(output_mount_path)).set_display_name(\"data-generation\")\n",
    "  \n",
    "    \n",
    "    retraining      = dkube_training_op(container=json.dumps({\"image\": \"docker.io/ocdr/d3-datascience-sklearn:v0.23.2\"}),\n",
    "                                    framework=\"sklearn\", version=\"0.23.2\",\n",
    "                                    program=str(training_program), run_script=training_script,\n",
    "                                    datasets=json.dumps([str(output_dataset)]),\n",
    "                                    input_dataset_mounts=json.dumps(output_mount_path),\n",
    "                                    models = json.dumps([str(model)]),\n",
    "                                    input_model_mounts = '[\"/model\"]',\n",
    "                                    outputs=json.dumps([str(output_model)]),\n",
    "                                    output_mounts='[\"/mm/retrained-model\"]',\n",
    "                                    auth_token=token).after(preprocessing).set_display_name(\"retraining\")\n",
    "    model_versioning = dkube_training_op(\n",
    "                                    auth_token=str(token),\n",
    "                                    framework=\"sklearn\", version=\"0.23.2\",\n",
    "                                    container=json.dumps({\"image\": \"ocdr/d3-datascience-sklearn:v0.23.2-1\"}),\n",
    "                                    program=str(training_program),\n",
    "                                    models = json.dumps([str(output_model)]),\n",
    "                                    input_model_mounts = '[\"/mm/retrained-model\"]',\n",
    "                                    outputs=json.dumps([str(model)]),\n",
    "                                    output_mounts='[\"/models\"]',\n",
    "                                    run_script=\"cp -r /mm/retrained-model/* /models/\").after(retraining).set_display_name(\"versioning\")\n",
    "\n",
    "    serving     = dkube_serving_op(model=model_versioning.outputs['artifact'], device='cpu', \n",
    "                                    serving_image=json.dumps({\"image\": \"ocdr/sklearnserver:0.23.2\"}),\n",
    "                                    transformer_image =json.dumps({\"image\": \"docker.io/ocdr/d3-datascience-sklearn:v0.23.2\"}),\n",
    "                                    transformer_project=str(training_program),\n",
    "                                    transformer_code='insurance/modeltraining/transformer.py', auth_token=token).after(model_versioning).set_display_name(\"serving\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.create_run_from_pipeline_func(insurance_retraining_pipeline, arguments={'token':token})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
