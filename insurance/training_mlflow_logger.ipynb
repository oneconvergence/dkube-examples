{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing as skpreprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import mlflow\n",
    "from mlflow.models.signature import infer_signature\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import requests, argparse\n",
    "requests.packages.urllib3.disable_warnings()\n",
    "\n",
    "from dkube.sdk.mlflow_logger import NotebookMlflowLogger\n",
    "nblogger = NotebookMlflowLogger()\n",
    "logger = nblogger.get_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MACROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = int(os.getenv(\"EPOCHS\", 10))\n",
    "\n",
    "LEARNING_RATE = float(os.getenv(\"LEARNING_RATE\", 0.01))\n",
    "\n",
    "MLFLOW_EXPERIMENT_NAME = os.getenv('DKUBE_PROJECT_NAME')\n",
    "\n",
    "#DATASET_URL could be specified as Environment parameters at the time of creating JL or Run\n",
    "\n",
    "# Define data\n",
    "INPUT_DATA_URL = os.getenv(\"DATASET_URL\", \"https://dkube-examples-data.s3.us-west-2.amazonaws.com/monitoring-insurance/training-data/insurance.csv\")\n",
    "\n",
    "\n",
    "# Keep track of models.\n",
    "OUTPUT_MODEL_DIR = os.getcwd()+\"/model_mlflow\"\n",
    "\n",
    "\n",
    "## create OUTPUT_MODEL_DIR\n",
    "if not os.path.exists(OUTPUT_MODEL_DIR):\n",
    "    os.makedirs(OUTPUT_MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLFLOW TRACKING INITIALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MLFLOW_EXPERIMENT_NAME:\n",
    "    exp = mlflow.get_experiment_by_name(MLFLOW_EXPERIMENT_NAME)\n",
    "    if not exp:\n",
    "        logger.info(\"Creating experiment...\")\n",
    "        mlflow.create_experiment(MLFLOW_EXPERIMENT_NAME)\n",
    "    mlflow.set_experiment(experiment_name=MLFLOW_EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(INPUT_DATA_URL)\n",
    "insurance_input = data.drop(['charges','timestamp','unique_id'],axis=1)\n",
    "insurance_target = data['charges']\n",
    "    \n",
    "for col in ['sex', 'smoker', 'region']:\n",
    "    if (insurance_input[col].dtype == 'object'):\n",
    "        le = skpreprocessing.LabelEncoder()\n",
    "        le = le.fit(insurance_input[col])\n",
    "        insurance_input[col] = le.transform(insurance_input[col])\n",
    "        logger.info(f'Completed Label encoding on {col}')\n",
    "    \n",
    "#standardize data\n",
    "x_scaled = StandardScaler().fit_transform(insurance_input)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_scaled,\n",
    "                                                    insurance_target.values,\n",
    "                                                    test_size = 0.25,\n",
    "                                                    random_state=1211)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)  #first we set random seed\n",
    "model = keras.Sequential([\n",
    "      layers.InputLayer(input_shape=(6)),\n",
    "      layers.Dense(64, activation='relu'),\n",
    "      layers.Dense(64, activation='relu'),\n",
    "      layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "model.compile(loss='mean_absolute_error',\n",
    "            optimizer=tf.keras.optimizers.Adam(lr=LEARNING_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow metric logging\n",
    "class loggingCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        mlflow.log_metric(\"train_loss\", logs[\"loss\"], step=epoch)\n",
    "        mlflow.log_metric(\"val_loss\", logs[\"val_loss\"], step=epoch)\n",
    "        # output accuracy metric for katib to collect from stdout\n",
    "        #print(f\"loss={round(logs['loss'],2)}\")\n",
    "        logger.info(f\"loss={round(logs['loss'],2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ML TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"insurance\") as run:\n",
    "    \n",
    "    model.fit(x_train, y_train, epochs = NUM_EPOCHS, verbose=0,\n",
    "                validation_split=0.1, callbacks=[loggingCallback()])\n",
    "    \n",
    "    # Exporting model\n",
    "    model.save(filepath=os.path.join(OUTPUT_MODEL_DIR, '1'))\n",
    "    \n",
    "    # Two ways to save model - log_artifacts() or log_model()\n",
    "    mlflow.log_artifacts(OUTPUT_MODEL_DIR) ## For tf-serving\n",
    "    signature = infer_signature(x_test, model.predict(x_test))\n",
    "    mlflow.keras.log_model(keras_model=model, artifact_path=None, signature=signature)\n",
    "        \n",
    "    # Record parameters\n",
    "    mlflow.log_params({\"dataset\": \"https://dkube-examples-data.s3.us-west-2.amazonaws.com/monitoring-insurance/training-data/insurance.csv\",\n",
    "                       \"code\": \"https://github.com/oneconvergence/dkube-examples/tree/training/insurance\",\n",
    "                       \"model\": \"Deep Neural Network\"})\n",
    "    logger.info(\"Training Complete !\")\n",
    "    nblogger.flush()  \n",
    "print(\"Training Complete !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
