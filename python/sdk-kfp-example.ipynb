{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dkube.sdk import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing feilds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = os.getenv('USERNAME')\n",
    "token = os.getenv('DKUBE_USER_ACCESS_TOKEN')\n",
    "inp_path = \"/opt/dkube/input\"\n",
    "out_path = \"/opt/dkube/output\"\n",
    "code_name = \"mnist-fs\"\n",
    "dataset_name = \"mnist\"\n",
    "training_fs = \"mnist-fs\"\n",
    "model_name = \"mnist\"\n",
    "framework = \"tensorflow_1.14\"\n",
    "image = \"ocdr/d3-datascience-tf-cpu:v1.14-3\"\n",
    "preprocess_script = f\"python featureset.py --fs {training_fs}\"\n",
    "training_script = f\"python model.py --fs {training_fs}\"\n",
    "transformer_script = \"tf/classification/mnist-fs/digits/transformer/transformer.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dkube Client handle\n",
    "api = DkubeApi(token=token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Adding code {code_name}\")\n",
    "code = DkubeCode(user, name=code_name)\n",
    "code.update_git_details(\"https://github.com/oneconvergence/dkubeio-examples/tree/master/tf/classification/mnist-fs/digits/classifier/program\")\n",
    "try:\n",
    "    api.create_code(code)\n",
    "    print(f\"Code {code_name} added\")\n",
    "except BaseException as e:\n",
    "    print(e)\n",
    "\n",
    "print(f\"Adding dataset {dataset_name}\")\n",
    "dataset = DkubeDataset(user, name=dataset_name)\n",
    "dataset.update_dataset_source(source='git')\n",
    "dataset.update_git_details(\"https://github.com/oneconvergence/dkubeio-examples-data/tree/master/tf/mnist\")\n",
    "try:\n",
    "    api.create_dataset(dataset)\n",
    "    print(f\"Dataset {dataset_name} added\")\n",
    "except BaseException as e:\n",
    "    print(e)\n",
    "\n",
    "print(f\"Adding featureset {training_fs}\")\n",
    "featureset = DkubeFeatureSet(name=training_fs)\n",
    "try:\n",
    "    api.create_featureset(featureset)\n",
    "    print(f\"Featureset {training_fs} added\")\n",
    "except BaseException as e:\n",
    "    print(e)\n",
    "    \n",
    "print(f\"Adding model {model_name}\")\n",
    "model = DkubeModel(user, name=model_name)\n",
    "model.update_model_source(source='dvs')\n",
    "try:\n",
    "    api.create_model(model)\n",
    "    print(f\"Model {model_name} added\")\n",
    "except BaseException as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required kfp imports and conponents load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import kfp.dsl as dsl\n",
    "import kfp.compiler as compiler\n",
    "from kubernetes import client as k8s_client\n",
    "from kfp import components\n",
    "import json\n",
    "from random import randint\n",
    "\n",
    "dkube_preprocess_op         = components.load_component_from_file(\"/mnt/dkube/pipeline/components/preprocess/component.yaml\")\n",
    "dkube_training_op           = components.load_component_from_file(\"/mnt/dkube/pipeline/components/training/component.yaml\")\n",
    "dkube_serving_op            = components.load_component_from_file(\"/mnt/dkube/pipeline/components/serving/component.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(\n",
    "    name='dkube-mnistfs-pl',\n",
    "    description='sample mnist featureset pipeline with dkube components'\n",
    ")\n",
    "def mnistfs_pipeline(\n",
    "    # Dkube user token\n",
    "    token = token, \n",
    "    # Code repo name which is added on Dkube platform\n",
    "    code_name = \"mnist-fs\",\n",
    "    # MNIST dataset name\n",
    "    dataset_name = \"mnist\",\n",
    "    # Featureset name\n",
    "    training_fs = \"mnist-fs\",\n",
    "    # Model name\n",
    "    model_name = \"mnist\"):\n",
    "    preprocessing = dkube_preprocess_op(token, json.dumps({\"image\": image}),\n",
    "                                program=code_name, run_script=preprocess_script,\n",
    "                                datasets = json.dumps([str(dataset_name)]), \n",
    "                                input_dataset_mounts = json.dumps([inp_path]),\n",
    "                                output_featuresets=json.dumps([str(training_fs)]), \n",
    "                                output_featureset_mounts=json.dumps([out_path])).set_display_name(\"MNIST Preprocessing\")\n",
    "    \n",
    "    training      = dkube_training_op(token, json.dumps({\"image\": image}),\n",
    "                            framework=\"tensorflow\", version=\"1.14\",\n",
    "                            program=code_name, run_script=training_script,\n",
    "                            featuresets=json.dumps([str(training_fs)]), outputs=json.dumps([str(model_name)]),\n",
    "                            input_featureset_mounts=json.dumps([inp_path]),\n",
    "                            output_mounts=json.dumps([out_path])).after(preprocessing).set_display_name(\"MNIST Training\")\n",
    "    \n",
    "    serving       = dkube_serving_op(token, training.outputs['artifact'],\n",
    "                            device=\"cpu\", serving_image=json.dumps({\"image\": \"ocdr/tensorflowserver:1.14\"}),\n",
    "                            transformer_image=json.dumps({\"image\": image}),\n",
    "                            transformer_project=code_name,\n",
    "                            transformer_code=transformer_script).after(training).set_display_name(\"MNIST Serving\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'Dkube- MNIST-FS pl'\n",
    "client = kfp.Client(existing_token=token)\n",
    "mnist_experiment = client.create_experiment(name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling and uploading pipeline(make sure the pipeline name is unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = {\"token\":token}\n",
    "compiler.Compiler().compile(mnistfs_pipeline, \"mnistfs-pipeline.zip\")\n",
    "try:\n",
    "    pipeline = client.upload_pipeline(\"mnistfs-pipeline.zip\", pipeline_name = \"mnist-fs-pipeline\")\n",
    "except BaseException as e:\n",
    "    print(e)\n",
    "runid = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating run from pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.run_pipeline(mnist_experiment.id, job_name=\"[MNIST] Run\" + str(runid), pipeline_id=pipeline.id, params=arguments)\n",
    "runid += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
