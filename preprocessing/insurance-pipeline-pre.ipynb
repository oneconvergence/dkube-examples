{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8f5e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "job_class = os.getenv(\"DKUBE_JOB_CLASS\")\n",
    "if not job_class:\n",
    "    !{sys.executable} -m pip install kfp >/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6214e00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import kfp\n",
    "from kfp import components\n",
    "from dkube.sdk.api import DkubeApi\n",
    "import random, string\n",
    "from termcolor import colored"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28945840",
   "metadata": {},
   "source": [
    "## Load the DKube Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70f8d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "dkube_training_op = components.load_component_from_file(\"/mnt/dkube/pipeline/components/training/component.yaml\")\n",
    "dkube_serving_op  = components.load_component_from_file(\"/mnt/dkube/pipeline/components/serving/component.yaml\")\n",
    "dkube_preprocess_op  = components.load_component_from_file(\"/mnt/dkube/pipeline/components/preprocess/component.yaml\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff153a93",
   "metadata": {},
   "source": [
    "## User Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a784969",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## These fields must be modified to allow the file to run based on your repo names\n",
    "## After the files are modified, run all of the cells to execute\n",
    "\n",
    "## Repo names for code, dataset & model\n",
    "code_repo = \"ins-lc-pre\"  # Change this to identify your Code Repo name\n",
    "dataset = \"ins-lc\"        # Change this to identify your Dataset Repo name\n",
    "model = \"ins-lc\"          # Change this to identify your Model Repo name\n",
    "\n",
    "## The script will create a name for you, but if you want to use your own name, enter it here\n",
    "pipeline_run_name = \"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e4364f6",
   "metadata": {},
   "source": [
    "## Other Variable Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34055c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "## These fields are specific to this example, and should not be modified\n",
    "\n",
    "## Get the environmental variables\n",
    "DKUBE_USERNAME = os.environ.get('DKUBE_USER_LOGIN_NAME')\n",
    "DKUBE_TOKEN = os.environ.get('DKUBE_USER_ACCESS_TOKEN')\n",
    "DKUBE_PROJECT_NAME = os.environ.get('DKUBE_PROJECT_NAME', 'insurance')\n",
    "\n",
    "# Check for preprocessing env var, which will be used later to run or skip preprocessing stage\n",
    "# Make the flag blank if not set during IDE creation\n",
    "PREPROCESS_FLAG = os.environ.get(\"PREPROCESS\", \"\")\n",
    "\n",
    "api = DkubeApi(token=DKUBE_TOKEN)\n",
    "\n",
    "## Project ID, make sure IDE is created under the same project where the expriment is suppose to run\n",
    "## Or else provide it manually in the project_id variable.\n",
    "project_id = os.environ.get(\"DKUBE_PROJECT_ID\")\n",
    "\n",
    "## Set the variables needed to execute the pipeline stages\n",
    "image = \"ocdr/dkube-datascience-tf-cpu:v2.0.0-17\"\n",
    "serving_image = \"ocdr/tensorflowserver:2.0.0\"\n",
    "\n",
    "preprocess_script = \"python insurance/preprocess.py\"\n",
    "training_script = \"python insurance/training-pre.py\"\n",
    "\n",
    "transformer_code='insurance/transformer.py'\n",
    "user = os.getenv('USERNAME')\n",
    "framework = \"tensorflow\"\n",
    "f_version = \"2.0.0\"\n",
    "\n",
    "## Get the list of versions for the input dataset & specify v1 to get original dataset for preprocessing\n",
    "dataset_version = api.get_dataset_versions(DKUBE_USERNAME, dataset)\n",
    "dataset_v1 = dataset_version[-1]['version']['uuid']\n",
    "preprocess_input_dataset_version = [dataset_v1]  \n",
    "\n",
    "# Set the mount paths\n",
    "input_dataset_mounts = [\"/input/dataset\"]\n",
    "output_dataset_mounts = [\"/output/dataset\"]\n",
    "\n",
    "output_mount_point = \"/opt/dkube/out\"\n",
    "\n",
    "run_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fae4a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(\n",
    "    name='dkube-insurance-pl',\n",
    "    description='sample insurance pipeline'\n",
    ")\n",
    "def insurance_pipeline(DKUBE_TOKEN, tags, deployment_name):\n",
    "    \n",
    "    # Look for PREPROCESS flag, and run the preprocess state it is anything but blank\n",
    "    if PREPROCESS_FLAG != '':\n",
    "        preprocess   = dkube_preprocess_op(DKUBE_TOKEN, json.dumps({\"image\": image}),\n",
    "                                    tags=tags,\n",
    "                                    program=code_repo, run_script=preprocess_script,\n",
    "                                    datasets=json.dumps([dataset]), input_dataset_mounts=input_dataset_mounts,\n",
    "                                    input_dataset_versions=preprocess_input_dataset_version,\n",
    "                                    outputs=json.dumps([dataset]),\n",
    "                                    output_mounts=output_dataset_mounts)\n",
    "\n",
    "        train       = dkube_training_op(DKUBE_TOKEN, json.dumps({\"image\": image}),\n",
    "                                    tags=tags,\n",
    "                                    framework=framework, version=f_version,\n",
    "                                    program=code_repo, run_script=training_script,\n",
    "                                    datasets=json.dumps([dataset]), input_dataset_mounts=input_dataset_mounts,\n",
    "                                    outputs=json.dumps([model]),\n",
    "                                    output_mounts=json.dumps([output_mount_point])).after(preprocess)\n",
    "    else:\n",
    "        # Otherwise, just run the training stage\n",
    "        train       = dkube_training_op(DKUBE_TOKEN, json.dumps({\"image\": image}),\n",
    "                                    tags=tags,\n",
    "                                    framework=framework, version=f_version,\n",
    "                                    program=code_repo, run_script=training_script,\n",
    "                                    datasets=json.dumps([dataset]), input_dataset_mounts=input_dataset_mounts,\n",
    "                                    outputs=json.dumps([model]),\n",
    "                                    output_mounts=json.dumps([output_mount_point]))      \n",
    "\n",
    "    # Run the serving stage either way\n",
    "    serving     = dkube_serving_op(DKUBE_TOKEN, train.outputs['artifact'], device='cpu', \n",
    "                                    name=deployment_name,\n",
    "                                    serving_image=json.dumps({\"image\": serving_image}),\n",
    "                                    transformer_image=json.dumps({\"image\": image}),\n",
    "                                    transformer_project=code_repo,\n",
    "                                    transformer_code=transformer_code,\n",
    "                                    production=\"true\").after(train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34f5f7a9",
   "metadata": {},
   "source": [
    "## Create a run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdebb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ''.join(random.choices(string.ascii_lowercase + string.digits, k=4))\n",
    "\n",
    "if project_id:\n",
    "    tags = json.dumps([f\"project:{project_id}\"])\n",
    "    project_name = os.environ.get(\"DKUBE_PROJECT_NAME\")\n",
    "\n",
    "    # Check for user-input pipeline run name, and if provided use it here, otherwise default it\n",
    "    if pipeline_run_name == \"\":\n",
    "        run_name = f\"[{project_name}] {DKUBE_USERNAME}:{code_repo} %s\"%res\n",
    "    else:\n",
    "        run_name = f\"{pipeline_run_name}\"\n",
    "\n",
    "    experiment = f\"[{project_name}] experiment\"\n",
    "    deployment_name = f\"{DKUBE_PROJECT_NAME}-{DKUBE_USERNAME}-%s\"%res\n",
    "else:\n",
    "    tags = []\n",
    "\n",
    "    # Check for user-input pipeline run name, and if provided use it here, otherwise default it\n",
    "    if pipeline_run_name == \"\":\n",
    "        run_name = f\"{DKUBE_USERNAME}:{code_repo} %s\"%res\n",
    "    else:\n",
    "        run_name = f\"{pipeline_run_name}\"\n",
    "\n",
    "    experiment = \"default\"\n",
    "    deployment_name = f\"{DKUBE_USERNAME}-%s\"%res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964f7610",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_id = api.get_deployment_id(name=deployment_name)\n",
    "if not deployment_id:\n",
    "    print(f\"On pipeline completion the deployment {colored(deployment_name, 'green', attrs=['bold'])} will be created\")\n",
    "    \n",
    "    client = kfp.Client(existing_token=DKUBE_TOKEN)\n",
    "    client.create_run_from_pipeline_func(insurance_pipeline, run_name=run_name, experiment_name=experiment,\n",
    "                                         arguments={\"DKUBE_TOKEN\":DKUBE_TOKEN, \"tags\":tags,\n",
    "                                                    'deployment_name':deployment_name}\n",
    "                                        )\n",
    "    run_id += 1\n",
    "    pl_config = {\"DEPLOYMENT_NAME\":deployment_name}\n",
    "    %store pl_config\n",
    "\n",
    "else:\n",
    "    print(\"Deployment Already Existing, skipping create, try running the cells again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4305ae20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
