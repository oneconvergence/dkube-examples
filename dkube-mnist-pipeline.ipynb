{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Dkube Pipelines SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/oneconvergence/dkube.git@pipelines-support --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install pipelines SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Please wait till this cell completes and then run next cells. This just need to be run once per active kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env RELEASE_VERSION=0.1.18\n",
    "!pip install https://storage.googleapis.com/ml-pipeline/release/${RELEASE_VERSION}/kfp.tar.gz --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import kfp pkgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import kfp.dsl as dsl\n",
    "import kfp.compiler as compiler\n",
    "from kubernetes import client as k8s_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List existing pipeline experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = kfp.Client()\n",
    "client.list_experiments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Dkube MNIST experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_experiment = client.create_experiment(name='Dkube - Mnist pl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define e2e MNIST Pipeline with Dkube components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp.dsl as dsl\n",
    "from kfp import components\n",
    "from kubernetes import client as k8s_client\n",
    "\n",
    "import os\n",
    "import json\n",
    "from random import randint\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'/opt/conda/lib/python3.7/site-packages')\n",
    "from dkube.pipelines import *\n",
    "\n",
    "dkube_training_op            = DkubeTrainOp(name='mnist-training')\n",
    "dkube_serving_op             = DkubeServeOp(name='mnist-serving')\n",
    "dkube_viewer_op              = DkubeViewerOp(name='mnist-inference')\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name='dkube-mnist-pl',\n",
    "    description='sample mnist digits pipeline with dkube components'\n",
    ")\n",
    "def d3pipeline(\n",
    "    #In notebook ACCESS_TOKEN is automatically picked up from env variable\n",
    "    auth_token  = os.getenv(\"ACCESS_TOKEN\"),\n",
    "    #By default tf v1.12 image is used here, v1.10, v1.11 or v1.13 can be used. \n",
    "    #Or any other custom image name can be supplied.\n",
    "    #For custom private images, please input username/password\n",
    "    training_container=json.dumps({'image':'docker.io/ocdr/dkube-datascience-tf-cpu:v1.12', 'username':'', 'password': ''}),\n",
    "    #Name of the workspace in dkube. Update accordingly if different name is used while creating a workspace in dkube.\n",
    "    training_program=\"mnist\",\n",
    "    #Script to run inside the training container    \n",
    "    training_script=\"python model.py\",\n",
    "    tuning = '{ \"studyName\": \"mnist-dkube-tuning\", \"owner\": \"crd\", \"optimizationtype\": \"maximize\", \"objectivevaluename\": \"train_accuracy_1\", \"optimizationgoal\": 0.99, \"requestcount\": 1, \"metricsnames\": [ \"train_accuracy_1\" ], \"parameterconfigs\": [ { \"name\": \"--learning_rate\", \"parametertype\": \"double\", \"feasible\": { \"min\": \"0.01\", \"max\": \"0.05\" } }, { \"name\": \"--batch_size\", \"parametertype\": \"int\", \"feasible\": { \"min\": \"100\", \"max\": \"200\" } }, { \"name\": \"--num_epochs\", \"parametertype\": \"int\", \"feasible\": { \"min\": \"1\", \"max\": \"10\" } } ] }',\n",
    "    #Input datasets for training. Update accordingly if different name is used while creating dataset in dkube.    \n",
    "    training_datasets=json.dumps([\"mnist\"]),\n",
    "    #Request gpus as needed. Val 0 means no gpu, then training_container=docker.io/ocdr/dkube-datascience-tf-cpu:v1.12    \n",
    "    training_gpus=0,\n",
    "    #Any envs to be passed to the training program    \n",
    "    training_envs=json.dumps([{\"steps\": 100}]),\n",
    "    #Device to be used for serving - dkube mnist example trained on gpu needs gpu for serving else set this param to 'cpu'\n",
    "    serving_device='cpu'):\n",
    "\n",
    "    train       = dkube_training_op(auth_token, training_container,\n",
    "                                    program=training_program, run_script=training_script,\n",
    "                                    datasets=training_datasets, ngpus=training_gpus,\n",
    "                                    envs=training_envs, tuning=tuning)\n",
    "    serving     = dkube_serving_op(auth_token, train.outputs['artifact'], device=serving_device).after(train)\n",
    "    inference   = dkube_viewer_op(auth_token, serving.outputs['servingurl'],\n",
    "                                  'digits', viewtype='inference').after(serving)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile and generate tar ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(d3pipeline, 'dkube_mnist_pl.tar.gz')\n",
    "# Upload this generated tarball into the Pipelines UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Run pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Click the dkube-training stage to see the enhanced Dkube Datascience dashboard, metrics and graphs. Click the dkube-viewer stage for the simple UI to test the model predecitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.run_pipeline(mnist_experiment.id, 'mnist_classifier_pipeline', 'dkube_mnist_pl.tar.gz', params={})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
