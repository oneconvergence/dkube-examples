name: dkube-job
description: |
    Component which can be used to run a user job with DKube resources.
metadata:
  annotations: {platform: 'Dkube'}
  labels: {platform: 'Dkube', logger: 'dkubepl', wfid: '{{workflow.uid}}', runid: '{{pod.name}}', stage: 'preprocess', dkube.garbagecollect: 'true', dkube.garbagecollect.policy: 'all'}
inputs:
  - {name: job_prefix,      type: String,   optional: false,
     description: 'Required. prefix to add to job name.'}
  - {name: auth_token,      type: String,   optional: false,
     description: 'Required. Dkube authentication token.'}
  - {name: container,       type: Dict,     optional: false,
     description: 'Required. Container to use for preprocessing. Format: {"image":<url>, "username":<>, "password":<>}'}
  - {name: program,         type: String,   default: '',
     description: 'Optional. Program imported in Dkube to be run inside container. If not specified container should have entrypoint.'}
  - {name: commit_id,         type: String,   default: '',
     description: 'Optional. Program commit ID. If not provided, dkube takes the latest commit.'}
  - {name: run_script,      type: String,   default: '',
     description: 'Optional. Script to run the program. If not specified container should have entrypoint.'}
  - {name: datasets,        type: List,     default: '[]',
     description: 'Optional. List of input datasets required for preprocessing. These datasets must be created in Dkube.'}
  - {name: input_dataset_mounts,        type: List,     default: '[]',
     description: 'Optional. List of input datasets mount paths.'}
  - {name: input_dataset_versions,        type: List,     default: '[]',
     description: 'Optional. List of input datasets versions.'}
  - {name: featuresets,        type: List,     default: '[]',
     description: 'Optional. List of input featuresets required for preprocessing. These featuresets must be created in Dkube.'}
  - {name: input_featureset_mounts,        type: List,     default: '[]',
     description: 'Optional. List of input featuresets mount paths.'}
  - {name: input_featureset_versions,        type: List,     default: '[]',
     description: 'Optional. List of input featureset versions.'}
  - {name: models,        type: List,     default: '[]',
     description: 'Optional. List of input models required for preprocessing. These models must be created in Dkube.'}
  - {name: input_model_mounts,        type: List,     default: '[]',
     description: 'Optional. List of input models mount paths.'}
  - {name: input_model_versions,        type: List,     default: '[]',
     description: 'Optional. List of input models versions.'}
  - {name: file_outputs,        type: Dict,     default: '{}',
     description: 'Optional. Dict containing output keys and paths'}
  - {name: envs,            type: List,     default: '[]',
     description: 'Optional. Environments for preprocess program. Exact key value will be made available for the container'}
  - {name: tags,        type: List,     default: '[]',
     description: 'Optional. List of user-chosen tags to allow Runs to be better identified or grouped.'}
outputs:
  - {name: rundetails,      description: 'Details of the dkube run'}
  - {name: artifact,        description: 'Identifier in Dkube storage where artifact generated by this component are stored.'}
  - {name: mlpipeline-ui-metadata, description: 'metadata file to display metrics'}
  - {name: output, description: 'output file from the job'}
implementation:
  container:
    image: ocdr/dkube_pylauncher:2.2 
    command: ["python3", "-u", "/dkubepl/main.py"]
    args: [
      {inputValue: job_prefix},
      {inputValue: auth_token},
      '{{workflow.uid}}',
      '{{pod.name}}',
      'job',
      --container, {inputValue: container},
      --script, {inputValue: run_script},
      --program, {inputValue: program},
      --commit_id, {inputValue: commit_id},
      --datasets, {inputValue: datasets},
      --input_dataset_mounts, {inputValue: input_dataset_mounts},
      --input_dataset_versions, {inputValue: input_dataset_versions},
      --featuresets, {inputValue: featuresets},
      --input_featureset_mounts, {inputValue: input_featureset_mounts},
      --input_featureset_versions, {inputValue: input_featureset_versions},
      --models, {inputValue: models},
      --input_model_mounts, {inputValue: input_model_mounts},
      --input_model_versions, {inputValue: input_model_versions},
      --envs, {inputValue: envs},
      --tags, {inputValue: tags},
      --output, {inputValue: file_outputs}
    ]
    fileOutputs:
      rundetails:   /tmp/rundetails
      artifact:     /tmp/artifact
      mlpipeline-ui-metadata: /metadata.json
      output: /output

